"""
í†µê³„ ì§‘ê³„ Lambda í•¨ìˆ˜
ë§¤ì¼ 1íšŒ ì‹¤í–‰ë˜ì–´ CloudWatch Logsë¥¼ ë¶„ì„í•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import boto3
import json
import os
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any
import requests

# AWS Lambda Powertools
from aws_lambda_powertools import Logger

# Powertools ì´ˆê¸°í™”
logger = Logger()

logs_client = boto3.client('logs')

ENVIRONMENT = os.environ.get('ENVIRONMENT', 'dev')
LOG_GROUP_NAME = f'/aws/lambda/profile-photo-ai-ImageProcess-{ENVIRONMENT}'
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL', '')


@logger.inject_lambda_context
def lambda_handler(event, context):
    """
    ë§¤ì¼ 1íšŒ ì‹¤í–‰ë˜ì–´ ì§€ë‚œ 24ì‹œê°„ í†µê³„ë¥¼ ì§‘ê³„í•˜ê³  ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬í¬íŠ¸ ìƒì„±
    """
    logger.info("ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘", environment=ENVIRONMENT)
    
    # ì§€ë‚œ 24ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=24)
    
    logger.info("ì¡°íšŒ ê¸°ê°„", start=start_time.isoformat(), end=end_time.isoformat())
    
    try:
        # 1. ìŠ¤íƒ€ì¼ë³„ ì´ë¯¸ì§€ ìƒì„± ìˆ˜ ì§‘ê³„
        logger.info("ìŠ¤íƒ€ì¼ë³„ í†µê³„ ì¡°íšŒ ì¤‘")
        style_stats = query_style_statistics(start_time, end_time)
        
        # 2. ì‹œê°„ëŒ€ë³„ ì‚¬ìš© íŒ¨í„´
        logger.info("ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ì¡°íšŒ ì¤‘")
        hourly_pattern = query_hourly_pattern(start_time, end_time)
        
        # 3. ì„±ê³µë¥  ë° ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
        logger.info("ì„±ê³µë¥  ì¡°íšŒ ì¤‘")
        success_rate = query_success_rate(start_time, end_time)
        
        # 4. ì²˜ë¦¬ ì‹œê°„ í†µê³„
        logger.info("ì²˜ë¦¬ ì‹œê°„ í†µê³„ ì¡°íšŒ ì¤‘")
        processing_times = query_processing_times(start_time, end_time)
        
        # 5. ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
        logger.info("ì‹¤íŒ¨ ì›ì¸ ì¡°íšŒ ì¤‘")
        failure_reasons = query_failure_reasons(start_time, end_time)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = generate_report(
            start_time, end_time,
            style_stats, hourly_pattern, success_rate, 
            processing_times, failure_reasons
        )
        
        # Discordë¡œ ë¦¬í¬íŠ¸ ì „ì†¡
        if DISCORD_WEBHOOK_URL:
            send_discord_report(report)
            logger.info("Discordë¡œ ë¦¬í¬íŠ¸ ì „ì†¡ ì™„ë£Œ")
        else:
            logger.warning("Discord Webhookì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ. ë¦¬í¬íŠ¸ëŠ” ë¡œê·¸ì—ë§Œ ê¸°ë¡ë¨")
            logger.info("ì¼ì¼ ë¦¬í¬íŠ¸", report=report)
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ',
                'timestamp': end_time.isoformat(),
                'period': {
                    'start': start_time.isoformat(),
                    'end': end_time.isoformat()
                }
            })
        }
        
    except Exception as e:
        logger.exception("ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ", error=str(e))
        
        return {
            'statusCode': 500,
            'body': json.dumps({
                'message': 'ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨',
                'error': str(e)
            })
        }


def query_style_statistics(start_time: datetime, end_time: datetime) -> List[List[Dict[str, str]]]:
    """
    CloudWatch Logs Insightsë¡œ ìŠ¤íƒ€ì¼ë³„ ìƒì„± ìˆ˜ ì¿¼ë¦¬
    """
    query = """
    fields @timestamp, style
    | filter event = "job_completed"
    | stats count() by style
    """
    
    return run_logs_insights_query(query, start_time, end_time)


def query_hourly_pattern(start_time: datetime, end_time: datetime) -> List[List[Dict[str, str]]]:
    """
    ì‹œê°„ëŒ€ë³„ ì‚¬ìš© íŒ¨í„´
    """
    query = """
    fields @timestamp
    | filter event = "job_completed"
    | stats count() as count by bin(1h) as hour
    """
    
    return run_logs_insights_query(query, start_time, end_time)


def query_success_rate(start_time: datetime, end_time: datetime) -> List[List[Dict[str, str]]]:
    """
    ì„±ê³µë¥  ë° ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
    """
    query = """
    fields @timestamp, event, errorType
    | filter event = "job_completed" or event = "job_failed"
    | stats 
        count() as total,
        sum(case when event = "job_completed" then 1 else 0 end) as success,
        sum(case when event = "job_failed" then 1 else 0 end) as failed
    """
    
    return run_logs_insights_query(query, start_time, end_time)


def query_processing_times(start_time: datetime, end_time: datetime) -> List[List[Dict[str, str]]]:
    """
    ì „ì²´ ì²˜ë¦¬ ì‹œê°„ í†µê³„ (ë‹¤ìš´ë¡œë“œ + ìƒì„± + ì—…ë¡œë“œ)
    """
    query = """
    fields @timestamp, processingTime
    | filter event = "job_completed"
    | stats avg(processingTime) as avg_total,
            pct(processingTime, 50) as p50,
            pct(processingTime, 95) as p95
    """
    
    return run_logs_insights_query(query, start_time, end_time)


def query_failure_reasons(start_time: datetime, end_time: datetime) -> List[List[Dict[str, str]]]:
    """
    ì‹¤íŒ¨ ì›ì¸ë³„ ì§‘ê³„
    """
    query = """
    fields @timestamp, errorType
    | filter event = "job_failed"
    | stats count() as count by errorType
    """
    
    return run_logs_insights_query(query, start_time, end_time)


def run_logs_insights_query(query: str, start_time: datetime, end_time: datetime) -> List[List[Dict[str, str]]]:
    """
    CloudWatch Logs Insights ì¿¼ë¦¬ ì‹¤í–‰
    """
    try:
        logger.debug("Logs Insights ì¿¼ë¦¬ ì‹œì‘", query_preview=query[:100])
        
        # ì¿¼ë¦¬ ì‹œì‘
        response = logs_client.start_query(
            logGroupName=LOG_GROUP_NAME,
            startTime=int(start_time.timestamp()),
            endTime=int(end_time.timestamp()),
            queryString=query
        )
        
        query_id = response['queryId']
        logger.debug("ì¿¼ë¦¬ ì‹œì‘ë¨", query_id=query_id)
        
        # ì¿¼ë¦¬ ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
        max_wait = 30
        elapsed = 0
        
        while elapsed < max_wait:
            result = logs_client.get_query_results(queryId=query_id)
            status = result['status']
            
            if status == 'Complete':
                logger.info("ì¿¼ë¦¬ ì™„ë£Œ", query_id=query_id, results_count=len(result['results']))
                return result['results']
            elif status == 'Failed' or status == 'Cancelled':
                raise Exception(f"ì¿¼ë¦¬ ì‹¤íŒ¨: {status}")
            
            time.sleep(1)
            elapsed += 1
        
        raise Exception(f"{max_wait}ì´ˆ í›„ ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ")
        
    except Exception as e:
        logger.error("Logs Insights ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜", error=str(e), query_preview=query[:100])
        return []


def generate_report(start_time, end_time, style_stats, hourly_pattern, success_rate, processing_times, failure_reasons):
    """
    ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬í¬íŠ¸ ìƒì„±
    """
    report_lines = []
    report_lines.append(f"# ğŸ“Š ProfilePhotoAI ì¼ì¼ ë¦¬í¬íŠ¸")
    report_lines.append(f"**ê¸°ê°„**: {start_time.strftime('%Y-%m-%d %H:%M')} ~ {end_time.strftime('%Y-%m-%d %H:%M')} (UTC)")
    report_lines.append("")
    
    # 1. ìŠ¤íƒ€ì¼ë³„ í†µê³„
    report_lines.append("## ğŸ¨ ìŠ¤íƒ€ì¼ë³„ ì´ë¯¸ì§€ ìƒì„± ìˆ˜")
    if style_stats:
        for row in style_stats:
            style = count = None
            for field in row:
                if field['field'] == 'style':
                    style = field['value']
                elif field['field'] == 'count()':
                    count = field['value']
            if style:
                report_lines.append(f"- **{style}**: {count}ê±´")
    else:
        report_lines.append("- ë°ì´í„° ì—†ìŒ")
    report_lines.append("")
    
    # 2. ì„±ê³µë¥ 
    report_lines.append("## âœ… ì„±ê³µë¥ ")
    if success_rate and len(success_rate) > 0:
        row = success_rate[0]
        total = success = failed = 0
        for field in row:
            if field['field'] == 'total':
                total = int(field['value'])
            elif field['field'] == 'success':
                success = int(field['value'])
            elif field['field'] == 'failed':
                failed = int(field['value'])
        
        success_rate_pct = (success / total * 100) if total > 0 else 0
        report_lines.append(f"- **ì „ì²´**: {total}ê±´")
        report_lines.append(f"- **ì„±ê³µ**: {success}ê±´ ({success_rate_pct:.1f}%)")
        report_lines.append(f"- **ì‹¤íŒ¨**: {failed}ê±´ ({100-success_rate_pct:.1f}%)")
    else:
        report_lines.append("- ë°ì´í„° ì—†ìŒ")
    report_lines.append("")
    
    # 3. ì‹¤íŒ¨ ì›ì¸
    report_lines.append("## âŒ ì‹¤íŒ¨ ì›ì¸")
    if failure_reasons:
        for row in failure_reasons:
            error_type = count = None
            for field in row:
                if field['field'] == 'errorType':
                    error_type = field['value']
                elif field['field'] == 'count':
                    count = field['value']
            if error_type:
                report_lines.append(f"- **{error_type}**: {count}ê±´")
    else:
        report_lines.append("- ì‹¤íŒ¨ ì—†ìŒ âœ¨")
    report_lines.append("")
    
    # 4. ì²˜ë¦¬ ì‹œê°„
    report_lines.append("## â±ï¸ í‰ê·  ì²˜ë¦¬ ì‹œê°„")
    if processing_times and len(processing_times) > 0:
        row = processing_times[0]
        for field in row:
            if field['field'] == 'avg_total':
                avg_ms = float(field['value'])
                report_lines.append(f"- **í‰ê· **: {avg_ms/1000:.1f}ì´ˆ")
            elif field['field'] == 'p50':
                p50_ms = float(field['value'])
                report_lines.append(f"- **P50**: {p50_ms/1000:.1f}ì´ˆ")
            elif field['field'] == 'p95':
                p95_ms = float(field['value'])
                report_lines.append(f"- **P95**: {p95_ms/1000:.1f}ì´ˆ")
    else:
        report_lines.append("- ë°ì´í„° ì—†ìŒ")
    report_lines.append("")
    
    # 5. ì‹œê°„ëŒ€ë³„ íŒ¨í„´
    report_lines.append("## ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ì‚¬ìš© íŒ¨í„´ (ìƒìœ„ 5ê°œ)")
    if hourly_pattern:
        # ì‹œê°„ëŒ€ë³„ë¡œ ì •ë ¬ (ì¹´ìš´íŠ¸ ë†’ì€ ìˆœ)
        sorted_hours = []
        for row in hourly_pattern:
            hour = count = None
            for field in row:
                if field['field'] == 'hour':
                    hour = field['value']
                elif field['field'] == 'count':
                    count = int(field['value'])
            if hour and count:
                sorted_hours.append((hour, count))
        
        sorted_hours.sort(key=lambda x: x[1], reverse=True)
        for i, (hour, count) in enumerate(sorted_hours[:5], 1):
            report_lines.append(f"{i}. **{hour[:13]}**: {count}ê±´")
    else:
        report_lines.append("- ë°ì´í„° ì—†ìŒ")
    
    return "\n".join(report_lines)


def send_discord_report(report_text):
    """
    Discord Webhookìœ¼ë¡œ ë¦¬í¬íŠ¸ ì „ì†¡
    """
    if not DISCORD_WEBHOOK_URL:
        logger.warning("Discord Webhook URLì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        return
    
    payload = {
        "content": report_text
    }
    
    try:
        response = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=10)
        if response.status_code == 204:
            logger.info("Discord Webhook ì „ì†¡ ì„±ê³µ")
        else:
            logger.warning("Discord Webhook ì „ì†¡ ì‹¤íŒ¨", status_code=response.status_code, response=response.text[:200])
    except Exception as e:
        logger.error("Discord Webhook ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", error=str(e))
